# Система автоматического распознавания жестов и движений

Полнофункциональная система для захвата, обработки и интерпретации жестов и движений человеческого тела в реальном времени.

## Описание системы

Система предназначена для автоматического захвата, обработки и интерпретации жестов и движений человеческого тела в реальном времени с целью преобразования их в машиночитаемые команды или данные. Ключевыми задачами являются обеспечение бесконтактного управления устройствами, взаимодействия с виртуальными и дополненными реальностями, анализа двигательной активности для фитнеса или реабилитации, а также повышения доступности интерфейсов для пользователей с ограниченными возможностями.

## Структура системы

Система состоит из пяти основных подсистем:

1. **Подсистема захвата данных** - получение исходных данных о положении и движении тела пользователя с помощью камеры и MediaPipe
2. **Подсистема предобработки данных** - фильтрация, сглаживание траекторий, идентификация и трекинг ключевых точек
3. **Подсистема распознавания и классификации** - идентификация конкретных жестов и движений на основе предобработанных данных
4. **Подсистема интерпретации и выполнения команд** - преобразование распознанных жестов в конкретные действия
5. **Интерфейсная подсистема** - пользовательские интерфейсы для калибровки, настройки и визуализации

## Пользователи системы

- **Разработчик приложений** - интегрирует API системы в программные продукты, настраивает соответствие жестов командам
- **Конечный пользователь** - взаимодействует с системой через камеру, используя жесты для управления интерфейсами
- **Специалист (реабилитолог, тренер)** - использует систему для анализа точности и правильности движений пользователя

## Основные сценарии использования

1. **Настройка жестового управления** - разработчик создает профиль, назначает жесты на команды, тестирует конфигурацию
2. **Использование в приложении** - пользователь выполняет движения перед камерой, система распознает их и передает команды
3. **Анализ техники движения** - специалист записывает движение, система сравнивает с эталоном и выдает отчет о точности

## Установка и запуск

### Требования

- Python 3.8+
- Веб-камера
- Windows/Linux/macOS

### Установка зависимостей

```bash
# Активация виртуального окружения (если используется)
# Windows PowerShell:
& ..\.venv\Scripts\Activate.ps1

# Windows CMD:
..\.venv\Scripts\activate.bat

# Linux/macOS:
source ../.venv/bin/activate

# Установка зависимостей
pip install -r requirements.txt
```

### Запуск системы

```bash
# Запуск сервера
uvicorn src.main:app --reload

# Или через Python
python src/main.py
```

Система будет доступна по адресу: `http://127.0.0.1:8000`

## Использование

### Веб-интерфейс

Откройте браузер и перейдите по адресу `http://127.0.0.1:8000`. Система предоставляет три режима работы:

#### 1. Режим пользователя
- Выполняйте жесты перед камерой
- Система распознает жесты и выполняет соответствующие действия
- Отображается список доступных жестов

#### 2. Режим разработчика
- Создавайте новые правила соответствия жестов командам
- Настраивайте типы действий (логирование, callback, эмуляция клавиатуры/мыши)
- Просматривайте и управляйте существующими правилами

#### 3. Режим специалиста
- Записывайте движения пользователя
- Анализируйте технику выполнения упражнений
- Получайте отчеты с рекомендациями по улучшению

### API Endpoints

#### Захват данных
- `GET /capture/status` - статус подсистемы захвата
- `WebSocket /capture/ws` - потоковая передача данных с камеры

#### Распознавание
- `POST /recognize` - распознавание жеста по landmarks
- `POST /recognize/batch` - пакетное распознавание последовательности

#### Настройки
- `GET /settings/info` - информация о системе
- `GET /settings/gestures` - список всех маппингов жестов
- `GET /settings/gestures/{gesture}` - маппинг конкретного жеста
- `POST /settings/gestures` - создание нового маппинга
- `PUT /settings/gestures/{gesture}` - обновление маппинга
- `DELETE /settings/gestures/{gesture}` - удаление маппинга

#### Запись и анализ
- `POST /record/sequence` - сохранение и анализ последовательности движений
- `GET /record/sequences/{label}` - получение истории записей для упражнения

#### Здоровье системы
- `GET /health` - проверка состояния системы

## Поддерживаемые жесты

- `raise_left_hand` - поднятие левой руки
- `raise_right_hand` - поднятие правой руки
- `both_hands_up` - обе руки подняты
- `clap` - хлопок
- `point_left` - указание влево
- `point_right` - указание вправо
- `hands_close` - руки близко друг к другу
- `wave_right` - мах правой рукой
- `wave_left` - мах левой рукой
- `circle_right` - круговое движение правой рукой

## Конфигурация

Настройки системы находятся в файле `src/app/config.py`. Основные параметры:

- `camera_device` - ID камеры (по умолчанию 0)
- `enable_hands_detection` - включение детекции рук
- `smoothing_window` - размер окна сглаживания
- `mappings_file` - путь к файлу маппингов жестов

Маппинги жестов хранятся в `configs/mappings.yaml` и могут быть изменены через веб-интерфейс или напрямую в файле.

## Структура проекта

```
OMIS_lab6/
├── src/
│   ├── main.py                 # Точка входа приложения
│   └── app/
│       ├── config.py           # Конфигурация
│       ├── routers/            # API роутеры
│       │   ├── capture.py      # Захват данных
│       │   ├── recognize.py    # Распознавание
│       │   ├── settings.py     # Настройки
│       │   ├── record.py       # Запись и анализ
│       │   └── health.py       # Здоровье системы
│       └── services/           # Бизнес-логика
│           ├── capture.py      # Сервис захвата
│           ├── preprocess.py   # Предобработка
│           ├── recognizer.py   # Распознавание жестов
│           └── interpret.py   # Интерпретация команд
├── web/                        # Веб-интерфейс
│   ├── index.html
│   ├── styles.css
│   └── script.js
├── configs/                    # Конфигурационные файлы
│   └── mappings.yaml          # Маппинги жестов
├── data/                       # Данные (создается автоматически)
│   └── sequences/             # Записанные последовательности
├── requirements.txt           # Зависимости Python
└── README.md                  # Документация
```

## Технологии

- **FastAPI** - веб-фреймворк для API
- **MediaPipe** - библиотека для детекции позы и жестов
- **OpenCV** - обработка видео
- **NumPy** - численные вычисления
- **WebSocket** - потоковая передача данных в реальном времени

## Разработка

### Добавление новых жестов

1. Расширьте класс `GestureRecognizer` в `src/app/services/recognizer.py`
2. Добавьте логику распознавания нового жеста в метод `recognize()`
3. Настройте маппинг жеста через веб-интерфейс или `configs/mappings.yaml`

### Добавление новых типов действий

1. Расширьте класс `InterpretationService` в `src/app/services/interpret.py`
2. Добавьте обработку нового типа действия в метод `execute()`
3. Обновите веб-интерфейс для поддержки нового типа

## Лицензия

Проект создан в образовательных целях.

## Контакты

Для вопросов и предложений создайте issue в репозитории проекта.
